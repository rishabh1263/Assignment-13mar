{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0333603d",
   "metadata": {},
   "source": [
    "##Q1:\n",
    "What are the assumption violations of ANOVA?\n",
    "Potential assumption violations include: Implicit factors: lack of independence within a sample. Lack of independence: lack of independence between samples. Outliers: apparent nonnormality by a few data points.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "215027ea",
   "metadata": {},
   "source": [
    "##Q2:\n",
    "What are the 3 types of ANOVA?\n",
    "This test is also called the Fisher analysis of variance. The use of ANOVA depends on the research design. Commonly, ANOVAs are used in three ways: one-way ANOVA, two-way ANOVA, and N-way ANOVA."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed7f2e99",
   "metadata": {},
   "source": [
    "Q3:\n",
    "What is the partitioning of variance in ANOVA?\n",
    "Image result for What is the partitioning of variance in ANOVA, and why is it important to understand this concept?\n",
    "An ANOVA uses an F-test to evaluate whether the variance among the groups is greater than the variance within a group. Another way to view this problem is that we could partition variance, that is, we could divide the total variance in our data into the various sources of that variation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "319aeed6",
   "metadata": {},
   "source": [
    "Q4:import numpy as np\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.formula.api import ols\n",
    "\n",
    "# create some sample data\n",
    "a = np.random.randint(1, 4, size=50)\n",
    "x = np.random.normal(loc=a, scale=1)\n",
    "\n",
    "# create a data frame\n",
    "df = sm.add_constant(pd.DataFrame({'x': x, 'a': a}))\n",
    "\n",
    "# fit the one-way ANOVA model\n",
    "model = ols('x ~ a', data=df).fit()\n",
    "\n",
    "# calculate the total sum of squares (SST)\n",
    "sst = np.sum((x - np.mean(x))**2)\n",
    "\n",
    "# calculate the explained sum of squares (SSE)\n",
    "sse = np.sum((model.fittedvalues - np.mean(x))**2)\n",
    "\n",
    "# calculate the residual sum of squares (SSR)\n",
    "ssr = np.sum(model.resid**2)\n",
    "\n",
    "# print results\n",
    "print(\"Total sum of squares (SST): {:.4f}\".format(sst))\n",
    "print(\"Explained sum of squares (SSE): {:.4f}\".format(sse))\n",
    "print(\"Residual sum of squares (SSR): {:.4f}\".format(ssr))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3ea6f07",
   "metadata": {},
   "source": [
    "Q5:\n",
    "import numpy as np\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.formula.api import ols\n",
    "\n",
    "# create some sample data\n",
    "a = np.random.randint(1, 4, size=100)\n",
    "b = np.random.randint(1, 4, size=100)\n",
    "x = np.random.normal(loc=a*b, scale=1)\n",
    "\n",
    "# create a data frame\n",
    "df = sm.add_constant(pd.DataFrame({'x': x, 'a': a, 'b': b}))\n",
    "\n",
    "# fit the two-way ANOVA model\n",
    "model = ols('x ~ C(a) + C(b) + C(a):C(b)', data=df).fit()\n",
    "\n",
    "# calculate the main effects\n",
    "main_a = model.params['C(a)[T.2]'] - model.params['C(a)[T.1]']\n",
    "main_b = model.params['C(b)[T.2]'] - model.params['C(b)[T.1]']\n",
    "\n",
    "# calculate the interaction effect\n",
    "interaction = model.params['C(a):C(b)[(1, 1)]'] - (model.params['C(a)[T.1]'] + model.params['C(b)[T.1]'])\n",
    "\n",
    "# print results\n",
    "print(\"Main effect of a: {:.4f}\".format(main_a))\n",
    "print(\"Main effect of b: {:.4f}\".format(main_b))\n",
    "print(\"Interaction effect: {:.4f}\".format(interaction))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79be04a3",
   "metadata": {},
   "source": [
    "If we conducted a one-way ANOVA and obtained an F-statistic of 5.23 and a p-value of 0.02, we can conclude that there is significant evidence to suggest that the means of the groups are different from each other. In other words, the null hypothesis that all group means are equal can be rejected.\n",
    "\n",
    "The F-statistic represents the ratio of the between-group variability to the within-group variability. A larger F-statistic indicates that the between-group variability is larger relative to the within-group variability, which suggests that the means of the groups are more different from each other. The p-value represents the probability of obtaining an F-statistic as extreme or more extreme than the observed one, assuming the null hypothesis is true. A p-value of 0.02 means that there is only a 2% chance of obtaining an F-statistic as extreme or more extreme than the observed one, assuming the null hypothesis is true.\n",
    "\n",
    "Therefore, we can interpret these results as strong evidence to suggest that the means of the groups are different from each other, and the observed differences are unlikely to be due to chance. We should investigate further to understand which groups are different from each other and the size of the differences. We can use post-hoc tests, such as Tukey's HSD test, to compare the means of the groups pairwise and identify significant differences."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48df59cc",
   "metadata": {},
   "source": [
    "Q7:\n",
    "In a repeated measures ANOVA, missing data can occur due to various reasons, such as participant dropout, technical difficulties during data collection, or incomplete responses. Handling missing data is crucial to avoid biased or inaccurate results. There are several methods to handle missing data in a repeated measures ANOVA:\n",
    "\n",
    "1. Complete case analysis (CCA): This method involves only including participants who have complete data for all time points. This is the default method in many statistical software packages. The potential consequence of using CCA is that it can result in a loss of statistical power and biased estimates if the missing data are not missing completely at random (MCAR).\n",
    "\n",
    "2. Pairwise deletion: This method involves analyzing the available data for each pair of time points separately. The potential consequence of using pairwise deletion is that it can also result in a loss of statistical power and biased estimates if the missing data are not MCAR.\n",
    "\n",
    "3. Mean imputation: This method involves replacing missing values with the mean value of the observed values for that variable. The potential consequence of using mean imputation is that it can lead to biased estimates and an underestimation of the standard error of the mean.\n",
    "\n",
    "4. Last observation carried forward (LOCF): This method involves imputing missing values with the last observed value for that participant. The potential consequence of using LOCF is that it can result in biased estimates and a loss of statistical power if the missing data are not MCAR.\n",
    "\n",
    "5. Multiple imputation (MI): This method involves imputing missing values multiple times to create several complete datasets and then analyzing each dataset separately. The results are combined using specific rules to produce an overall estimate. MI is considered the gold standard for handling missing data because it can reduce bias and provide accurate estimates if the missing data are not MCAR.\n",
    "\n",
    "In summary, handling missing data in a repeated measures ANOVA is crucial to avoid biased or inaccurate results. Using different methods to handle missing data can lead to different estimates and levels of statistical power, and the choice of method should depend on the underlying missing data mechanism and the research question of interest. Multiple imputation is considered the gold standard for handling missing data but may not always be feasible."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c7395c7",
   "metadata": {},
   "source": [
    "Q8:\n",
    "\n",
    "Using Post Hoc Tests with ANOVA\n",
    "By Jim Frost 125 Comments\n",
    "\n",
    "Post hoc tests are an integral part of ANOVA. When you use ANOVA to test the equality of at least three group means, statistically significant results indicate that not all of the group means are equal. However, ANOVA results do not identify which particular differences between pairs of means are significant. Use post hoc tests to explore differences between multiple group means while controlling the experiment-wise error rate.\n",
    "\n",
    "In this post, I’ll show you what post hoc analyses are, the critical benefits they provide, and help you choose the correct one for your study. Additionally, I’ll show why failure to control the experiment-wise error rate will cause you to have severe doubts about your results."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5252ebae",
   "metadata": {},
   "source": [
    "Q9:\n",
    "import scipy.stats as stats\n",
    "import pandas as pd\n",
    "\n",
    "# Create a dataframe with the weight loss data\n",
    "data = pd.DataFrame({\n",
    "    'diet': ['A']*20 + ['B']*15 + ['C']*15,\n",
    "    'weight_loss': [3.2, 2.5, 2.7, 3.8, 2.1, 2.9, 2.4, 3.1, 3.6, 3.3,\n",
    "                    2.7, 3.0, 3.1, 3.3, 3.2, 2.6, 2.8, 2.9, 3.5, 2.6,\n",
    "                    2.3, 2.5, 2.6, 3.3, 3.0, 2.5, 2.4, 2.1, 2.8, 2.7,\n",
    "                    1.9, 2.0, 2.1, 2.4, 2.2, 2.5, 2.3, 2.6, 2.9, 2.5,\n",
    "                    1.8, 1.9, 2.0, 2.1, 2.3, 2.6, 2.7, 2.8, 2.2, 2.1]\n",
    "})\n",
    "\n",
    "# Check the descriptive statistics of the weight loss data\n",
    "print(data.groupby('diet')['weight_loss'].describe())\n",
    "\n",
    "# Perform the one-way ANOVA\n",
    "f_stat, p_value = stats.f_oneway(data[data['diet'] == 'A']['weight_loss'],\n",
    "                                 data[data['diet'] == 'B']['weight_loss'],\n",
    "                                 data[data['diet'] == 'C']['weight_loss'])\n",
    "print(\"F-statistic:\", f_stat)\n",
    "print(\"p-value:\", p_value)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df07b86e",
   "metadata": {},
   "source": [
    "Q10import pandas as pd\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "\n",
    "control_scores = np.array([70, 75, 80, 65, 73, 72, 68, 74, 78, 77, 72, 71, 75, 70, 68, 76, 73, 72, 75, 74, 73, 71, 70, 69, 72, 73, 76, 75, 74, 72, 71, 74, 77, 73, 75, 72, 76, 70, 72, 71, 75, 73, 69, 72, 74, 76, 77, 71, 73, 75, 74, 72, 73, 72, 75, 70, 72, 73, 77, 75, 74, 73, 71, 72, 70, 75, 76, 73, 74, 72, 71, 70, 76, 73, 72, 70, 75, 72, 73, 71, 74, 75, 77, 72, 74, 70, 73, 75, 76, 71, 70, 73, 75, 72, 74, 76, 77, 75, 71, 73, 70, 72])\n",
    "experimental_scores = np.array([75, 77, 82, 80, 85, 78, 79, 83, 84, 86, 78, 81, 77, 79, 82, 84, 83, 85, 77, 81, 79, 82, 80, 83, 85, 81, 78, 84, 79, 80, 77, 82, 81, 79, 83, 80, 82, 78, 81, 80, 83, 82, 79, 84, 85, 77, 80, 79, 78, 82, 83, 84, 85, 79, 83, 80, 82, 81, 83, 79, 78, 82, 83, 81, 84, 80, 78, 85, 79, 83, 82, 84, 80, 81, 77, 79, 82, 81, 85, 84, 80, 83, 79, 82, 84, 78, 77, 85, 81, 80, 82, 83, 84, 79, 78, 81, 77, 83])\n",
    "control_mean = np.mean(control_scores)\n",
    "experimental_mean = np.mean(experimental_scores)\n",
    "control_std = np.std(control_scores, ddof=1)\n",
    "experimental_std = np.std(experimental_scores, ddof=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "29c56526",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "unexpected indent (3216334167.py, line 11)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"C:\\Users\\Rishabh Singh\\AppData\\Local\\Temp\\ipykernel_18336\\3216334167.py\"\u001b[1;36m, line \u001b[1;32m11\u001b[0m\n\u001b[1;33m    sales_data_melted = pd.melt(sales_data.reset_index(), id_vars=['index'], value_vars=['Store A', 'Store B', 'Store C'])\u001b[0m\n\u001b[1;37m    ^\u001b[0m\n\u001b[1;31mIndentationError\u001b[0m\u001b[1;31m:\u001b[0m unexpected indent\n"
     ]
    }
   ],
   "source": [
    "##Q12:\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.formula.api import ols\n",
    "from statsmodels.stats.multicomp import pairwise_tukeyhsd\n",
    "\n",
    "sales_data = pd.DataFrame({'Store A': [100, 120, 115, 110, 125, 130, 105, 115, 120, 130, 135, 110, 125, 130, 105, 115, 120, 130, 135, 110, 125, 130, 105, 115, 120, 130, 135, 110, 125, 130],\n",
    "                           'Store B': [80, 95, 90, 100, 105, 110, 85, 95, 100, 105, 110, 90, 100, 105, 85, 95, 100, 105, 110, 90, 100, 105, 85, 95, 100, 105, 110, 90, 100, 105],\n",
    "                           'Store C': [60, 75, 70, 80, 85, 90, 65, 75, 80, 85, 90, 70, 80, 85, 65, 75, 80, 85, 90, 70, 80, 85, 65, 75, 80, 85, 90, 70, 80, 85]})\n",
    "                            sales_data_melted = pd.melt(sales_data.reset_index(), id_vars=['index'], value_vars=['Store A', 'Store B', 'Store C'])\n",
    "sales_data_melted.columns = ['Day', 'Store', 'Sales']\n",
    "model = ols('Sales ~ C(Store) + C(Day)', data=sales_data_melted).fit()\n",
    "anova_table = sm.stats.anova_lm(model, typ=2)\n",
    "print(anova_table)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d648d669",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
